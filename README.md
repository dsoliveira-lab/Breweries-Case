# BEES Data Engineering 
## ğŸº Data Project â€“ Breweries Case

Este repositÃ³rio contÃ©m a estrutura de um projeto de dados, tendo por objetivo a avaliaÃ§Ã£o das habilidades em consumir dados de uma API, transformando-os e persistindo-os em um data lake seguindo a arquitetura medalhÃ£o com trÃªs camadas: dados brutos(Bronze), dados selecionados particionado por localizaÃ§Ã£o(Silver) e uma camada analÃ­tica agregada(Gold).  Integrando o Apache Airflow, Minio, Postgres e Metabase. Utilizando uma infra-estrutura de conteninerizaÃ§Ã£o(Docker), boas praticas de programaÃ§Ã£o(Python) e DocumentaÃ§Ã£o, alem da criaÃ§Ã£o de repositorio e versionamento do mesmo.
 
Bons estudos e bebam Ã¡guağŸ’¦!

## ğŸ“Š Arquitetura da Pipeline
Abaixo estÃ¡ a representaÃ§Ã£o grÃ¡fica da arquitetura deste projeto:

![Desenho Arquitetura](./image/Diagrama_Project_BEES.png)

Nesta arquitetura, os dados sÃ£o extraÃ­dos de uma unica fonte(API), contendo dados semi-estruturados. Os dados serÃ£o transformados e carregados em um DataLake, e finalmente consumidos por ferramentas de visualizaÃ§Ã£o como o Metabase.

## ğŸ“‚ Estrutura do Projeto
A estrutura do projeto estÃ¡ organizada da seguinte maneira:

```
/ENG_DADOS_PROJETO1
â”‚
â”œâ”€â”€ .temp/                               # Nessa pasta existe os arquivos que utilizei para exploraÃ§Ã£o dos dados inicialmente, e tratamentos realizados em Spark
â”‚   â”œâ”€â”€ bs_bronze.parquet
â”‚   â””â”€â”€ bs_silver.parquet
â”‚   â””â”€â”€ explo.ipynb
â”‚   â””â”€â”€ trf_bs_bronze_to_bs_silver.ipynb
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ config_airflow/
â”‚   â”‚   â””â”€â”€ airflow.Dockerfile           # Dockerfile customizado para o Airflow
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ dag_main.py                  # Arquivo principal da DAG contendo as extraÃ§Ãµes e as transformaÃ§Ãµes em dbt.
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ task_bronze.py               # Arquivo de task contendo a extraÃ§Ã£o dos dados vindos da API <https://api.openbrewerydb.org/breweries>, salvando-os na camada bronze.
â”‚   â”‚   â””â”€â”€ task_silver.py               # Arquivo de task contendo os dados coletados na camada_bronze, transformaÃ§Ãµes e particionamentos, salvando os dados na camada silver.
â”‚   â”‚   â””â”€â”€ task_gold.py                 # Arquivo de task contendo dos dados coletados em silver, com resposta a pergunta feita no projeto. 
â”œâ”€â”€ docker-compose.yaml                  # Estrutura e requisitos iniciais em conteirner do projeto.
â”œâ”€â”€ .gitgnore                            # Arquivo .git para ignorar arquivos e diretorios que nÃ£o sÃ£o necessÃ¡rios para utilizaÃ§Ã£o do projeto.
â”œâ”€â”€ requirements.txt                     # Responsavel pelas lib's principais para a criaÃ§Ã£o do projeto.
â”œâ”€â”€ README.md                            # DocumentÃ§Ã£o do projeto, utilizada para o entendimento e funcionamento do mesmo.
```

## ğŸ› ï¸ Tecnologias Utilizadas 
- **API**: Dados semi-estruturados, utilizados na pratica do projeto.
- **Apache Airflow**: Para orquestraÃ§Ã£o de workflows e automaÃ§Ã£o de tarefas.
- **Docker**: Para containerizaÃ§Ã£o de serviÃ§os, garantindo um ambiente isolado e reprodutÃ­vel.
- **MinIO**: Comparado ao S3 da AWS, servirÃ¡ para o armazenamento oferecendo escalabilidade, disponibilidade dos dados, seguranÃ§a e performance. 
- **Postgres**: Banco de dados utilizado como Data Lake para armazenar as tabelas nas suas diferentes camadas. 
- **Metabase**: Ferramenta de BI para visualizaÃ§Ã£o e anÃ¡lise dos dados armazenados no Data Warehouse.

## ğŸ³ Docker
O projeto estÃ¡ configurado para rodar em um ambiente Docker. O `docker-compose.yaml` e o `Dockerfile` na raiz do projeto sÃ£o usados para configurar o ambiente de desenvolvimento e execuÃ§Ã£o dos serviÃ§os. AlÃ©m disso, o Airflow possui um `Dockerfile` customizado para garantir que todas as dependÃªncias especÃ­ficas sejam atendidas.

![docker](./image/docker.png)

## ![airflow2](https://github.com/user-attachments/assets/513d0d86-7aa4-4dc8-8086-702037b91348) Airflow
- **DAGs**: As DAGs (Directed Acyclic Graphs) sÃ£o definidas dentro da pasta `airflow/dags/`. O arquivo principal Ã© o `dag_main.py`, que orquestra as diferentes tarefas.
- **Tasks**: As tarefas sÃ£o modularizadas dentro da pasta `airflow/tasks/`. Um exemplo Ã© o `task_nome_camada.py`, que pode conter lÃ³gica para processar arquivos parquet.
- **ConfiguraÃ§Ãµes**: Todas as configuraÃ§Ãµes e customizaÃ§Ãµes especÃ­ficas do Airflow estÃ£o na pasta `airflow/config_airflow/`.

![airflow](./image/airflow.png)
  
## ![s3](https://github.com/user-attachments/assets/0ce8f052-5282-4433-8421-24ba2493448b) MinIO
- **Armazenamento**: UtilizaÃ§Ã£o e armazenamento dos dados na utilizaÃ§Ã£o dos buckets bronze, silver e gold. Atendendo aos requisitos solicitados no escopo do projeto.
- **MedalhÃ£o**: PadrÃ£o de design de dados usado em um datalake, com o objetivo de melhorar incremental e progressivamente a estrutura e qualidade das camadas(Bronze â‡’ Silver â‡’ Gold) da arquitetura.
- **ConfiguraÃ§Ãµes**: Todas as configuraÃ§Ãµes e customizaÃ§Ãµes especÃ­ficas do Metabase estÃ£o no arquivo `docker-compose.yml`.

![minio](./image/minio.png)

## ![metabase](https://github.com/user-attachments/assets/02627285-44d7-4475-9e71-15079d4d0b0e) Metabase
- **Data-Viz**: CriaÃ§Ã£o e disponibilidade de visualizaÃ§Ã£o de dados, conexÃ£o com o postgres, atendendo assim aos mais diversos tipos de consumidores.
- **Users**: ConfiguraÃ§Ã£o de controle de acesso as camadas por grupo de usuÃ¡rios.
- **ConfiguraÃ§Ãµes**: Todas as configuraÃ§Ãµes e customizaÃ§Ãµes especÃ­ficas do Metabase estÃ£o no arquivo `docker-compose.yml`.

## ğŸš€ Como iniciar

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/wuldson-franco/breweries_case.git
   ```
2. Navegue atÃ© o diretÃ³rio do projeto:
   ```bash
   cd breweries_case
   ```
3. Suba os containers com Docker:
   ```bash
   docker-compose up -d
   ```
4. Acesse o Airflow na URL e inicie as DAGs conforme necessÃ¡rio.
    ```bash
   http://localhost:8080
   ```
5. Apague os containers Docker:
   ```bash
   docker-compose down -v
   ``` 

## ğŸ“š DocumentaÃ§Ã£o

- [DocumentaÃ§Ã£o Oficial do Airflow](https://airflow.apache.org/docs/)
- [DocumentaÃ§Ã£o Oficial do Docker](https://docs.docker.com)
- [DocumentaÃ§Ã£o Oficial do MinIO](https://min.io/docs/kes/)
- [DocumentaÃ§Ã£o Oficial do Metabase](https://www.metabase.com/docs/latest/)

## ğŸ“‹ ContribuiÃ§Ãµes e Duvidas

ContribuiÃ§Ãµes e duvidas sÃ£o bem-vindas, qualquer coisa manda msg!

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [MIT License](LICENSE).
